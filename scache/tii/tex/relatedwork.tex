\section{Related Work}\label{related}

{\color{black}
\textbf{Modeling} 
% Most representative DAG computing frameworks use similar \textit{Bulk Synchronize Parallel} (BSP)\cite{valiant1990bridging} model to control data synchronization in each computing phase. 
% , i.e., \textit{stage} in Spark, \textit{superstep} in Pregel\cite{malewicz2010pregel} and so on. 
% (Hadoop MapReduce can also be considered as a special case of only one superstep in BSP model). 
% In the process of optimizing the shuffle phases between adjacent computing phases, we design a performance model to assist in analyzing computing process.
% There are also lots of performance models for MapReduce have been proposed, such as \cite{verma2011aria, khan2016hadoop, herodotou2011hadoop, chen2014cresp, farhat2016stochastic}.
% Verma et al. \cite{verma2011aria} proposed the ARIA model to estimate the required resources based on the job information, the amount of input data and a specified soft deadline.
Khan et al. \cite{khan2016hadoop} proposed the HP model which extends the ARIA model. The HP model adds scaling factors and uses a simple linear regression to estimate the job execution time on larger datasets.
% In \cite{herodotou2011hadoop}, Herodotou proposed a detailed set of mathematical performance models for describing the five phases of a MapReduce job and combine them into an overall MapReduce job model.
% The execution is separated into the phases: Read, Map, Collect, Spill, Merge, Shuffle, Merge, and Reduce. 
% The set of performance models describe each above-mentioned phases and combine into an overall MapReduce job model. 
Chen et al. \cite{chen2014cresp} proposed the CRESP model which is a cost model that estimates the performance of a job then 
% provisions the resources for the job.
Farshid Farhat et al.\cite{farhat2016stochastic} proposed a closed-form queuing model which focuses on stragglers and try to optimize them. 
% The proposed model is parameterized by the task inter-arrival times to the mappers, the delayed tailed service times, and the number of mappers, which is used to optimize the stragglers. 
% \cite{khan2016hadoop, farhat2016stochastic, chen2014cresp} have proposed several methods to model the DAG computing process.
However, the above models are not able to accurately describe the overhead caused by the shuffle process under different scheduling strategies. 
% Different from these models, our FRQ model quantifies computing and I/O resources and visualizes them in the time dimension. 
The FRQ model focuses on describing the overhead caused by the shuffle process in different scheduling strategies, which satisfies our demand.

\textbf{Industrial big-data}
% In the \textit{Industry 4.0} which leading by the German Government, industrial big-data refers to a huge amount of time-series data which generated by industrial equipment in smart factories.
Industrial big-data refers to huge time-series data generated by industrial equipment in smart factories.
More than 1000 Exabytes industrial data is annually generated by smart factories and the data is expected to increase 20-fold in the next ten years \cite{yin2015big}.
Nowadays, the real challenge of big-data is not how to collect it, but how to manage it logically and efficiently \cite{lv2017next}.
Several distributed computing frameworks become efficient tools in industrial big-data analysis \cite{lade2017manufacturing, li2016scientific, ur2018big}.
}


\textbf{Pre-scheduling} 
Slow-start from Apache Hadoop MapReduce is a classic approach to handle shuffle overhead. 
% Starfish \cite{starfish} gets sampled data statics for self-tuning system parameters (e.g. slow-start, etc). 
% DynMR \cite{dynmr} dynamically starts reduce tasks in late map stage. 
% All of them have the explicit I/O time in occupied slots. 
% SCache instead starts shuffle pre-fetching without consuming slots. 
iShuffle \cite{guo2017ishuffle} decouples shuffle from reducers and designs a centralized shuffle controller. 
% But it can neither handle multiple shuffles nor schedule multiple rounds of reduce tasks. 
iHadoop \cite{ihadoop} aggressively pre-schedules tasks in multiple successive stages to start fetching shuffle. 
% Besides \textit{slow-start} from Hadoop MapReduce, \cite{starfish, ihadoop, guo2017ishuffle, dynmr} have also proposed several methods to improve the DAG frameworks.
However, we have proved that randomly assigned tasks may hurt the overall performance in Section \ref{randomassign}. 
Different from these works, SCache pre-schedules multiple shuffles without breaking load balancing. 

%  by combining DAG information and heuristic algorithms.
% \textbf{Delay-scheduling} 
% Delay Scheduling \cite{delay} delays tasks assignment to get better data locality, which can reduce the network traffic. 
% ShuffleWatcher \cite{shufflewatcher} delays shuffle fetching when the network is saturated. 
% At the same time, it achieves better data locality. 
% Both Quincy \cite{quincy} and Fair Scheduling \cite{preemptive} can reduce shuffle data by optimizing data locality of map tasks. 
% But all of them cannot mitigate explicit I/O in both map and reduce tasks. 
% In addition, their optimizations fluctuate under different network performances and data distributions, whereas SCache can provide a stable performance gain by shuffle data pre-fetching and in-memory caching.

\textbf{Network layer optimization} 
% Varys \cite{varys} and Aalo \cite{aalo} also provide the network layer optimization for shuffle transfer. 
% BASS\cite{qin2017bandwidth} combines SDN (Software-defined networking) with Hadoop and provides a bandwidth-aware task scheduling to optimize shuffle phases.
% Hybrid SDN \cite{huang2018survey} can also be seen as a solution to improve the performance.
% We think that it can be applied on SCache to further improve the performace.
% To increase the scalability, hybrid SDN\cite{huang2018survey} can 
% Though the efforts above are limited throughout whole shuffle process, they can be easily applied on SCache to further improve the performance.
% Varys \cite{varys} and Aalo \cite{aalo} also provide the network layer optimization for shuffle transfer. 
% Though the efforts are limited throughout whole shuffle process, they can be easily applied on SCache to further improve the performance.
According to \cite{qin2017bandwidth, huang2018survey}, we can also combine SDN with SCache to further improve the performance on the network later.